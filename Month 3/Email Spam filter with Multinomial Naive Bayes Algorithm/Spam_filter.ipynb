{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Spam filter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYgEjQWwuJ9J",
        "colab_type": "text"
      },
      "source": [
        "# Email Spam Filter with Multinomial Naive Bayes\n",
        "In this project, I am going to build an email spam filter with naive bayes algorithms. My goal is to write a program that classifies new emails with an accuracy greater than 90% — so I expect that more than 90% of the new messages will be classified correctly as spam or non-spam.\n",
        "To train the algorithm, we'll use a dataset of 5728 emails that are already classified by humans, the dataset was gotten from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1fNUvbzuJ9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfXT3YQouJ94",
        "colab_type": "text"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjQTF-dGuJ-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "def f(fname):\n",
        "    x = files.upload()\n",
        "    return x[fname]\n",
        "f('emails.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnqbpCnfu9xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emails = pd.read_csv('emails.csv')\n",
        "emails.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3LIZ2WquJ-p",
        "colab_type": "code",
        "outputId": "1c8780ff-39d4-4c1e-9a1a-79e535f0320b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(emails)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OsErfA7uJ_C",
        "colab_type": "text"
      },
      "source": [
        "The dataframe contains just 2 columns, the <b>text</b> column containing the email subject and the <b>spam</b> column containing 1s and 0s where 1 means the message is spam while 0 means the message is non_spam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5QkQQiJuJ_G",
        "colab_type": "code",
        "outputId": "9d7b7cc2-eb22-4a6d-a808-3baf5946a7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "emails['spam'].value_counts(normalize=True) * 100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    76.117318\n",
              "1    23.882682\n",
              "Name: spam, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZEx3bvjuJ_Y",
        "colab_type": "text"
      },
      "source": [
        "Above, about 77% of all the messages are not spam and the remaining 23% are spam. This sample looks represntative, since in practice most messages that people receive are non_spam.\n",
        "\n",
        "# Data Cleaning\n",
        "To calculate all the probabilities required by the algorithm, we'll first need to perform a bit of data cleaning to bring the data in a format that will allow us to extract easily all the information we need.\n",
        "\n",
        "Remove Punctuation and special characters\n",
        "\n",
        "We'll begin with removing all the punctuation.\n",
        "The text column contains a text that isnt part of the main message, the word 'Subject'. I'm going to remove it from the messages so that the algorithm will have only the necessary data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J61FC4CZuJ_c",
        "colab_type": "code",
        "outputId": "c4e87d66-208e-4756-f88c-73177d8f4966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "emails['text'].head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Subject: naturally irresistible your corporate...\n",
              "1    Subject: the stock trading gunslinger  fanny i...\n",
              "2    Subject: unbelievable new homes made easy  im ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DgvpFAGuJ_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emails['text'] = emails['text'].str.replace('Subject:', '').str.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZaHgn27uKAP",
        "colab_type": "code",
        "outputId": "25d64741-4a11-45d8-ac2a-a01696e4767b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "emails['text'] = emails['text'].str.replace('.', '').str.replace('*', '').str.replace(',', '').str.replace(':', '').str.replace('-', '').str.strip()\n",
        "emails['text']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       naturally irresistible your corporate identity...\n",
              "1       the stock trading gunslinger  fanny is merrill...\n",
              "2       unbelievable new homes made easy  im wanting t...\n",
              "3       4 color printing special  request additional i...\n",
              "4       do not have money  get software cds from here ...\n",
              "                              ...                        \n",
              "5723    re  research and development charges to gpg  h...\n",
              "5724    re  receipts from visit  jim   thanks again fo...\n",
              "5725    re  enron case study update  wow ! all on the ...\n",
              "5726    re  interest  david   please  call shirley cre...\n",
              "5727    news  aurora 5  2 update  aurora version 5  2 ...\n",
              "Name: text, Length: 5728, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiyKYKGEuKAg",
        "colab_type": "text"
      },
      "source": [
        "The messages that has been classified as spam are labelled 1, whereas the non-spam messages have been labelled as 0. about 77% of the dataset are non_spam messages while only 23% are spam messages.\n",
        "\n",
        "The next step is to creating our spam filter, the first thing to do is to split the dataset into the training and test sets;\n",
        "\n",
        "- A training set, which we'll use to \"train\" the computer how to classify messages.\n",
        "- A test set, which we'll use to test how good the spam filter is with classifying new messages.\n",
        "\n",
        "I would be splitting the dataset in a ratio 80:20 for the training set and test set repectively to train the algorithm with as much data as possible but with still enough data to test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs6hw5EjuKAq",
        "colab_type": "code",
        "outputId": "0a2aca83-44cb-40ca-8cf7-5ef1ce488ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Randomize the dataset\n",
        "emails_randomized = emails.sample(frac=1, random_state=1)\n",
        "\n",
        "# Calculate index for split\n",
        "training_test_index = round(len(emails_randomized) * 0.8)\n",
        "\n",
        "# Training/Test split\n",
        "training_set = emails_randomized[:training_test_index].reset_index(drop=True)\n",
        "test_set = emails_randomized[training_test_index:].reset_index(drop=True)\n",
        "\n",
        "print(training_set.shape)\n",
        "print(test_set.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4582, 2)\n",
            "(1146, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63BkTr-HuKBC",
        "colab_type": "code",
        "outputId": "6180f529-6af7-4af9-b99a-6f3238d33781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#check the percentage of the training set just to confirm\n",
        "training_set['spam'].value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.75993\n",
              "1    0.24007\n",
              "Name: spam, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoApZftZuKBd",
        "colab_type": "code",
        "outputId": "5f7542d1-40c2-4da6-c401-adb21f3f0279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "test_set['spam'].value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.766143\n",
              "1    0.233857\n",
              "Name: spam, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M2G8HRiuKB6",
        "colab_type": "text"
      },
      "source": [
        "# Creating the Vocabulary\n",
        "\n",
        "Let's now move to creating the vocabulary, which in this context means a list with all the unique words in our training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psswilfuuKB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set['text'] = training_set['text'].str.split()\n",
        "\n",
        "vocabulary = []\n",
        "for text in training_set['text']:\n",
        "    for word in text:\n",
        "        vocabulary.append(word)\n",
        "        \n",
        "vocabulary = list(set(vocabulary))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoG4PsA1uKCN",
        "colab_type": "code",
        "outputId": "d0e75898-fef5-4576-840a-3363285faaf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocabulary)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34188"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBg8Id7BuKCj",
        "colab_type": "text"
      },
      "source": [
        "It looks like there are 34,188 unique words in all the messages of the training set.\n",
        "\n",
        "Now going to use the vocabulary just created to make the data transformation we want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbn8UfxauKCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "len_training_set = len(training_set['text'])\n",
        "\n",
        "word_counts_per_text = {unique_word: np.zeros (len_training_set, dtype=np.int32) for unique_word in vocabulary}\n",
        "\n",
        "for index, text in enumerate(training_set['text']):\n",
        "    for word in text:\n",
        "        word_counts_per_text[word][index] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W906IjYuKDD",
        "colab_type": "code",
        "outputId": "999c27c9-bb16-416c-bb1c-6cbaee2baea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "word_counts = pd.DataFrame(word_counts_per_text)\n",
        "word_counts.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>calpx</th>\n",
              "      <th>pete</th>\n",
              "      <th>nominating</th>\n",
              "      <th>ability</th>\n",
              "      <th>marshall</th>\n",
              "      <th>lumber</th>\n",
              "      <th>referee</th>\n",
              "      <th>adds</th>\n",
              "      <th>upper</th>\n",
              "      <th>label</th>\n",
              "      <th>therfore</th>\n",
              "      <th>georganne</th>\n",
              "      <th>refuses</th>\n",
              "      <th>screechy</th>\n",
              "      <th>012501</th>\n",
              "      <th>continues</th>\n",
              "      <th>slowed</th>\n",
              "      <th>specifiers</th>\n",
              "      <th>mathews</th>\n",
              "      <th>trademark</th>\n",
              "      <th>does</th>\n",
              "      <th>redoubtable</th>\n",
              "      <th>karine</th>\n",
              "      <th>puhca</th>\n",
              "      <th>amiry</th>\n",
              "      <th>oom</th>\n",
              "      <th>356</th>\n",
              "      <th>grumulaitis</th>\n",
              "      <th>feasiblity</th>\n",
              "      <th>496</th>\n",
              "      <th>ukrpi</th>\n",
              "      <th>bette</th>\n",
              "      <th>insiders</th>\n",
              "      <th>lengthens</th>\n",
              "      <th>boland</th>\n",
              "      <th>appropriately</th>\n",
              "      <th>502373</th>\n",
              "      <th>308</th>\n",
              "      <th>zaprzeczenie</th>\n",
              "      <th>dorn</th>\n",
              "      <th>...</th>\n",
              "      <th>155</th>\n",
              "      <th>computable</th>\n",
              "      <th>caboose</th>\n",
              "      <th>entity</th>\n",
              "      <th>goup</th>\n",
              "      <th>curso</th>\n",
              "      <th>godzinie</th>\n",
              "      <th>customs</th>\n",
              "      <th>councils</th>\n",
              "      <th>keep</th>\n",
              "      <th>haigh</th>\n",
              "      <th>1917</th>\n",
              "      <th>talkington</th>\n",
              "      <th>mataya</th>\n",
              "      <th>347</th>\n",
              "      <th>deem</th>\n",
              "      <th>sparkling</th>\n",
              "      <th>ebrochure</th>\n",
              "      <th>hedland</th>\n",
              "      <th>intel</th>\n",
              "      <th>ondarza</th>\n",
              "      <th>neural</th>\n",
              "      <th>marking</th>\n",
              "      <th>whitebook</th>\n",
              "      <th>ord</th>\n",
              "      <th>spacial</th>\n",
              "      <th>wives</th>\n",
              "      <th>3652</th>\n",
              "      <th>markswv</th>\n",
              "      <th>jewels</th>\n",
              "      <th>kmart</th>\n",
              "      <th>objected</th>\n",
              "      <th>driven</th>\n",
              "      <th>muzzy</th>\n",
              "      <th>31212</th>\n",
              "      <th>parcel</th>\n",
              "      <th>toronto</th>\n",
              "      <th>116</th>\n",
              "      <th>ridge</th>\n",
              "      <th>heuristically</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 34188 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   calpx  pete  nominating  ability  ...  toronto  116  ridge  heuristically\n",
              "0      0     0           0        0  ...        0    0      0              0\n",
              "1      0     0           0        0  ...        0    0      0              0\n",
              "2      0     0           0        0  ...        0    0      0              0\n",
              "3      0     0           0        0  ...        0    0      0              0\n",
              "4      0     0           0        0  ...        0    0      0              0\n",
              "\n",
              "[5 rows x 34188 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXWOcLUHuKDT",
        "colab_type": "code",
        "outputId": "d5db5f87-d0e9-434f-daa0-e0d4a9b56924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
        "training_set_clean.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e1d772f72c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_set_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_counts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraining_set_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_set' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcVSC1cluKDu",
        "colab_type": "text"
      },
      "source": [
        "# Calculating Constants First\n",
        "I am now done with cleaning the training set, and can begin creating the spam filter. The Naive Bayes algorithm will need to answer these two probability questions to be able to classify new messages.\n",
        "\n",
        "- Probabilty that the message is spam given the vocabulary; P(Spam|w1,w2,w3...wn)\n",
        "- Probabilty that the message is no_spam given the vocabulary; P(non_spam|w1,w2,w3...wn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "aJ4iM8tZuKD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Isolating spam and ham messages first\n",
        "spam_messages = training_set_clean[training_set_clean['spam'] == 1]\n",
        "non_spam_messages = training_set_clean[training_set_clean['spam'] == 0]\n",
        "\n",
        "# P(Spam) and P(non_spam)\n",
        "p_spam = len(spam_messages) / len(training_set_clean)\n",
        "p_non_spam = len(non_spam_messages) / len(training_set_clean)\n",
        "\n",
        "# N_Spam\n",
        "n_words_per_spam_message = spam_messages['text'].apply(len)\n",
        "n_spam = n_words_per_spam_message.sum()\n",
        "\n",
        "# N_Non_spam\n",
        "n_words_per_non_spam_message = non_spam_messages['text'].apply(len)\n",
        "n_non_spam = n_words_per_non_spam_message.sum()\n",
        "\n",
        "# N_Vocabulary\n",
        "n_vocabulary = len(vocabulary)\n",
        "\n",
        "# Laplace smoothing\n",
        "alpha = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muSRbZ7tuKEG",
        "colab_type": "text"
      },
      "source": [
        "# Calculating Parameters\n",
        "Now that the constant terms have been calculated above, I can move on with calculating the parameters P(wi|Spam)  and P(wi|non_spam) . Each parameter will thus be a conditional probability value associated with each word in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_GwSqx3uKEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initiate parameters\n",
        "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
        "parameters_non_spam = {unique_word:0 for unique_word in vocabulary}\n",
        "\n",
        "# Calculate parameters\n",
        "for word in vocabulary:\n",
        "    n_word_given_spam = spam_messages[word].sum()   # spam_messages already defined in a cell above\n",
        "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
        "    parameters_spam[word] = p_word_given_spam\n",
        "    \n",
        "    n_word_given_non_spam = non_spam_messages[word].sum()   # ham_messages already defined in a cell above\n",
        "    p_word_given_non_spam = (n_word_given_non_spam + alpha) / (n_non_spam + alpha*n_vocabulary)\n",
        "    parameters_non_spam[word] = p_word_given_non_spam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuhYiyTBuKEX",
        "colab_type": "text"
      },
      "source": [
        "# Classifying A New Message\n",
        "Now that we have all our parameters calculated, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
        "\n",
        "Takes in as input a new message (w1, w2, ..., wn).\n",
        "Calculates P(Spam|w1, w2, ..., wn) and P(non_spam|w1, w2, ..., wn).\n",
        "Compares the values of P(Spam|w1, w2, ..., wn) and P(non_spam|w1, w2, ..., wn), and:\n",
        "If P(non_spam|w1, w2, ..., wn) > P(Spam|w1, w2, ..., wn), then the message is classified as ham.\n",
        "If P(non_spam|w1, w2, ..., wn) < P(Spam|w1, w2, ..., wn), then the message is classified as spam.\n",
        "If P(non_spam|w1, w2, ..., wn) = P(Spam|w1, w2, ..., wn), then the algorithm may request human help."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKa75-5JuKEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def classify(message):\n",
        "    '''\n",
        "    message: a string\n",
        "    '''\n",
        "    \n",
        "    message = email['text'].str.replace('.', '').str.replace('*', '').str.replace(',', '').str.replace(':', '').str.replace('-', '').str.strip()\n",
        "    message = message.split()\n",
        "    \n",
        "    p_spam_given_message = p_spam\n",
        "    p_non_spam_given_message = p_non_spam\n",
        "\n",
        "    for word in message:\n",
        "        if word in parameters_spam:\n",
        "            p_spam_given_message *= parameters_spam[word]\n",
        "            \n",
        "        if word in parameters_ham:\n",
        "            p_non_spam_given_message *= parameters_non_spam[word]\n",
        "            \n",
        "    print('P(Spam|message):', p_spam_given_message)\n",
        "    print('P(non_spam|message):', p_non_spam_given_message)\n",
        "    \n",
        "    if p_non_spam_given_message > p_spam_given_message:\n",
        "        print('Label: Non_spam')\n",
        "    elif p_non_spam_given_message < p_spam_given_message:\n",
        "        print('Label: Spam')\n",
        "    else:\n",
        "        print('Equal proabilities, have a human classify this!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm-zfBBbuKE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa1S0dR2uKFN",
        "colab_type": "text"
      },
      "source": [
        "# Measuring the Spam Filter's Accuracy\n",
        "The two results above look promising, but let's see how well the filter does on our test set, which has 1,146 messages.\n",
        "\n",
        "We'll start by writing a function that returns classification labels instead of printing them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BI8EVZ8uKFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify_test_set(message):    \n",
        "    '''\n",
        "    message: a string\n",
        "    '''\n",
        "    \n",
        "    #message = re.sub('\\W', ' ', message)\n",
        "    #message = message.lower().split()\n",
        "    \n",
        "    p_spam_given_message = p_spam\n",
        "    p_non_spam_given_message = p_non_spam\n",
        "\n",
        "    for word in message:\n",
        "        if word in parameters_spam:\n",
        "            p_spam_given_message *= parameters_spam[word]\n",
        "            \n",
        "        if word in parameters_non_spam:\n",
        "            p_non_spam_given_message *= parameters_non_spam[word]\n",
        "    \n",
        "    if p_non_spam_given_message > p_spam_given_message:\n",
        "        return 'non_spam'\n",
        "    elif p_spam_given_message > p_non_spam_given_message:\n",
        "        return 'spam'\n",
        "    else:\n",
        "        return 'needs human classification'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhSCjWx6uKFl",
        "colab_type": "text"
      },
      "source": [
        "Now that there is a function that returns labels instead of printing them, we can use it to create a new column in our test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU-jlq1WuKFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set['predicted'] = test_set['text'].apply(classify_test_set)\n",
        "test_set.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1aEk7Y5uKF6",
        "colab_type": "text"
      },
      "source": [
        "Now, I'll write a function to measure the accuracy of the spam filter to find out how well the spam filter does."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEi3jmKruKF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = test_set.shape[0]\n",
        "    \n",
        "for row in test_set.iterrows():\n",
        "    row = row[1]\n",
        "    if row['spam'] == row['predicted']:\n",
        "        correct += 1\n",
        "        \n",
        "print('Correct:', correct)\n",
        "print('Incorrect:', total - correct)\n",
        "print('Accuracy:', correct/total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gyxCIVEuKGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}